{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akarshaurora/anaconda3/envs/eeg_decoding/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Hostname dhcp-10-29-160-100.dyn.MIT.EDU not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n"
     ]
    }
   ],
   "source": [
    "from config import Config\n",
    "from datasets import BroderickDataset\n",
    "from preprocessor import Preprocessor\n",
    "from utils import prepare_inputs, EEGDataset\n",
    "from model import EEGAdapterLlamaForCausalLM\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/broderick/EEG/\n",
      "datasets/broderick/Stimuli/Text/\n",
      "Retrieving S01...\n",
      "Processing S01...\n",
      "datasets/brennan_hale/EEG/\n",
      "datasets/brennan_hale/Stimuli/Text/\n",
      "Retrieving S01...\n",
      "datasets/broderick/EEG/\n",
      "datasets/broderick/Stimuli/Text/\n",
      "Retrieving S01...\n"
     ]
    }
   ],
   "source": [
    "config = Config(\"config/config.yaml\")\n",
    "EEG = BroderickDataset(config)\n",
    "PROCESSOR = Preprocessor(config, EEG=EEG)\n",
    "eegs, subjects, inputs, labels = prepare_inputs(config, *PROCESSOR['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:58<00:00, 29.04s/it]\n",
      "/Users/akarshaurora/anaconda3/envs/eeg_decoding/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/Users/akarshaurora/anaconda3/envs/eeg_decoding/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "braindecoder = EEGAdapterLlamaForCausalLM(config, config.llama.model_name, config.llama.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen Parameter: encoder.merger.heads, Size: torch.Size([270, 2048])\n",
      "Frozen Parameter: encoder.initial_linear.0.weight, Size: torch.Size([270, 270, 1])\n",
      "Frozen Parameter: encoder.initial_linear.0.bias, Size: torch.Size([270])\n",
      "Frozen Parameter: encoder.subject_layers.weights, Size: torch.Size([33, 270, 270])\n",
      "Frozen Parameter: encoder.final.0.weight, Size: torch.Size([640, 320, 1])\n",
      "Frozen Parameter: encoder.final.0.bias, Size: torch.Size([640])\n",
      "Frozen Parameter: encoder.final.2.weight, Size: torch.Size([640, 1024, 1])\n",
      "Frozen Parameter: encoder.final.2.bias, Size: torch.Size([1024])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.0.0.weight, Size: torch.Size([320, 270, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.0.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.0.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.0.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.1.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.1.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.1.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.1.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.2.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.2.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.2.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.2.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.3.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.3.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.3.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.3.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.4.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.4.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.4.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.4.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.5.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.5.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.5.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.5.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.6.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.6.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.6.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.6.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.7.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.7.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.7.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.7.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.8.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.8.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.8.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.8.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.9.0.weight, Size: torch.Size([320, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.9.0.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.9.1.weight, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.sequence.9.1.bias, Size: torch.Size([320])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.1.0.weight, Size: torch.Size([640, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.1.0.bias, Size: torch.Size([640])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.3.0.weight, Size: torch.Size([640, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.3.0.bias, Size: torch.Size([640])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.5.0.weight, Size: torch.Size([640, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.5.0.bias, Size: torch.Size([640])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.7.0.weight, Size: torch.Size([640, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.7.0.bias, Size: torch.Size([640])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.9.0.weight, Size: torch.Size([640, 320, 3])\n",
      "Frozen Parameter: encoder.encoders.meg.glus.9.0.bias, Size: torch.Size([640])\n",
      "Parameter: projector.linear_proj.weight, Size: torch.Size([4096, 1024])\n",
      "Parameter: projector.linear_proj.bias, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.embed_tokens.weight, Size: torch.Size([32000, 4096])\n",
      "Frozen Parameter: model.model.layers.0.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.0.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.0.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.0.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.0.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.0.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.0.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.0.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.0.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.1.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.1.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.1.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.1.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.1.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.1.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.1.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.1.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.1.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.2.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.2.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.2.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.2.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.2.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.2.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.2.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.2.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.2.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.3.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.3.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.3.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.3.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.3.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.3.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.3.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.3.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.3.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.4.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.4.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.4.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.4.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.4.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.4.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.4.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.4.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.4.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.5.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.5.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.5.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.5.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.5.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.5.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.5.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.5.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.5.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.6.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.6.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.6.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.6.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.6.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.6.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.6.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.6.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.6.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.7.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.7.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.7.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.7.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.7.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.7.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.7.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.7.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.7.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.8.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.8.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.8.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.8.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.8.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.8.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.8.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.8.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.8.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.9.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.9.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.9.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.9.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.9.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.9.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.9.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.9.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.9.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.10.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.10.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.10.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.10.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.10.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.10.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.10.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.10.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.10.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.11.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.11.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.11.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.11.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.11.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.11.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.11.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.11.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.11.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.12.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.12.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.12.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.12.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.12.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.12.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.12.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.12.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.12.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.13.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.13.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.13.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.13.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.13.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.13.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.13.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.13.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.13.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.14.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.14.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.14.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.14.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.14.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.14.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.14.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.14.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.14.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.15.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.15.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.15.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.15.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.15.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.15.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.15.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.15.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.15.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.16.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.16.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.16.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.16.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.16.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.16.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.16.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.16.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.16.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.17.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.17.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.17.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.17.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.17.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.17.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.17.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.17.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.17.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.18.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.18.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.18.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.18.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.18.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.18.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.18.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.18.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.18.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.19.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.19.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.19.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.19.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.19.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.19.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.19.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.19.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.19.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.20.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.20.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.20.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.20.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.20.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.20.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.20.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.20.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.20.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.21.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.21.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.21.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.21.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.21.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.21.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.21.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.21.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.21.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.22.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.22.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.22.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.22.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.22.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.22.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.22.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.22.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.22.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.23.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.23.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.23.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.23.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.23.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.23.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.23.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.23.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.23.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.24.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.24.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.24.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.24.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.24.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.24.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.24.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.24.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.24.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.25.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.25.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.25.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.25.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.25.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.25.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.25.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.25.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.25.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.26.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.26.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.26.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.26.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.26.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.26.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.26.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.26.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.26.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.27.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.27.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.27.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.27.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.27.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.27.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.27.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.27.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.27.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.28.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.28.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.28.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.28.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.28.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.28.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.28.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.28.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.28.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.29.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.29.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.29.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.29.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.29.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.29.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.29.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.29.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.29.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.30.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.30.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.30.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.30.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.30.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.30.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.30.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.30.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.30.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.31.self_attn.q_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.31.self_attn.k_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.31.self_attn.v_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.31.self_attn.o_proj.weight, Size: torch.Size([4096, 4096])\n",
      "Frozen Parameter: model.model.layers.31.mlp.gate_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.31.mlp.up_proj.weight, Size: torch.Size([11008, 4096])\n",
      "Frozen Parameter: model.model.layers.31.mlp.down_proj.weight, Size: torch.Size([4096, 11008])\n",
      "Frozen Parameter: model.model.layers.31.input_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.layers.31.post_attention_layernorm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.model.norm.weight, Size: torch.Size([4096])\n",
      "Frozen Parameter: model.lm_head.weight, Size: torch.Size([32000, 4096])\n"
     ]
    }
   ],
   "source": [
    "for name, param in braindecoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter: {name}, Size: {param.size()}\")\n",
    "    else:\n",
    "        print(f\"Frozen Parameter: {name}, Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(eegs, subjects, inputs, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "optimizer = Adam(braindecoder.parameters(), lr=config.train.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg.shape: torch.Size([1, 61, 360])\n",
      "subject.shape: torch.Size([1])\n",
      "input_ids: torch.Size([1, 100])\n",
      "label_ids: torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "for (eeg, subject, input_data), label in dataloader:\n",
    "    print(f'eeg.shape: {eeg.shape}')\n",
    "    print(f'subject.shape: {subject.shape}')\n",
    "    print(f'input_ids: {input_data.shape}')\n",
    "    print(f'label_ids: {label.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6452,  287,\n",
      "         2307, 8023, 1497,  817,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "18.26792335510254\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, optimizer, epochs, device):\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for (eeg, subject, input_data), labels in dataloader:\n",
    "            eeg = eeg.to(device)\n",
    "            input_data = input_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_data, labels=labels, eegs=eeg.float(), subject_index=subject)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            print(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "train(braindecoder, dataloader, optimizer, config.train.epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_decoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
