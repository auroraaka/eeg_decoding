datasets:
  resampled_fs: 120
  interval: 3
  target_channels: 61
  path: "datasets"
  brennan_hale: 
    path: "brennan_hale"
    subjects: ["S01"]
    original_fs: 500
    num_channels: 61
  broderick:
    path: "broderick"
    subjects: ["S01", "S02", "S03", "S04", "S05", "S06", "S07", "S08", "S09", "S10", "S11", "S12", "S13", "S14", "S15", "S16", "S17", "S18", "S19"]
    original_fs: 128
    num_channels: 128

preprocessor:
  baseline_length: 0.5
  stft_flag: False
  nperseg: 50
  noverlap: 25
  normalizing: "zscore"
  return_onesided: True

encoder:
  checkpoint_path: "checkpoint/checkpoint.th"
  meta_config_path: "config/meta_config.yaml"
  clip_conv_config_path: "config/clip_conv.yaml"
  out_channels: 10
  in_features: 1024
  out_features: 4096
  pool_size: 30
  freeze: True

llama:
  model_name: "NousResearch/Llama-2-7b-hf"
  token: None
  max_length: 100
  hidden_dim: 4096
  freeze: True

tokenizer:
  prompt: "Find the best match for the following sequence:"
  ignore_prompt: True
  max_length: 100
  model_max_length: 100
  truncation: True
  return_tensors: "pt"
  padding: "longest"
  padding_side: "right"
  return_attention_mask: True

train:
  batch_size: 32
  epochs: 10
  learning_rate: 0.0001
  weight_decay: 0.01
  device: "cuda"
  seed: 42

ablations:
  random_features: false
  random_encoder: false

studies:
  path: "studies"